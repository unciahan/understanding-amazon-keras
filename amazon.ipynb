{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tqdm import tqdm\n",
    "from tensorflow_addons.metrics import FBetaScore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "\n",
    "df_train = pd.read_csv('/content/train_v2.csv')\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "labels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n",
    "\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "\n",
    "print(f'{labels}\\n{label_map}\\n{inv_label_map}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tags in tqdm(df_train.values, miniters=1000):\n",
    "    img = cv2.imread(f'/content/train-jpg/{i}.jpg')\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    x_train.append(cv2.resize(img, (32, 32)))\n",
    "    y_train.append(targets)\n",
    "    \n",
    "y_train = np.array(y_train, np.uint8)\n",
    "x_train = np.array(x_train, np.float16) / 255\n",
    "\n",
    "print(f'{x_train.shape}\\n{y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 35000\n",
    "x_train, x_valid, y_train, y_valid = x_train[:split], x_train[split:], y_train[:split], y_train[split:]\n",
    "\n",
    "print(f'x_train : {x_train.shape} \\ny_train : {y_train.shape}')\n",
    "print(f'x_valid : {x_valid.shape} \\ny_valid : {y_valid.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbeta = FBetaScore(\n",
    "        num_classes=len(labels),\n",
    "        average='weighted',\n",
    "        beta=2.0,\n",
    "        threshold=0.2,\n",
    "        name='fbeta')\n",
    "\n",
    "def model_efficientnet_b0(input_shape=(32, 32, 3), weight_path=None):\n",
    "    backbone = EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=input_shape))\n",
    "    model.add(backbone)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(17, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer='adam',\n",
    "        metrics=[fbeta, tf.keras.metrics.AUC()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = model_efficientnet_b0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "lr_decay = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.2, \n",
    "    patience=3, \n",
    "    verbose=1, \n",
    "    mode='auto', \n",
    "    epsilon=0.0001, \n",
    "    cooldown=0, \n",
    "    min_lr=0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hist = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    validation_data=(x_valid, y_valid),callbacks=[es,mc,lr_decay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(model_hist.history['loss']) + 1)\n",
    "\n",
    "plt.figure(figsize = (9, 6))\n",
    "plt.plot(epochs, model_hist.history['fbeta'])\n",
    "plt.title('Train History')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Result')\n",
    "plt.legend(['F-beta Score'])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
